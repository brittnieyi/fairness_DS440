{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Set up feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.ethics.ex4 import *\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Load the data, separate features from target\ndata = pd.read_csv(\"../input/synthetic-credit-card-approval/synthetic_credit_card_approval.csv\")\nX = data.drop([\"Target\"], axis=1)\ny = data[\"Target\"]\n\n# Break into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n\n# Preview the data\nprint(\"Data successfully loaded!\\n\")\nX_train.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-04T23:04:43.982912Z","iopub.execute_input":"2022-11-04T23:04:43.983373Z","iopub.status.idle":"2022-11-04T23:04:45.103894Z","shell.execute_reply.started":"2022-11-04T23:04:43.983334Z","shell.execute_reply":"2022-11-04T23:04:45.102634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset contains, for each applicant:\n\n* income (in the Income column),\n* the number of children (in the Num_Children column),\n* whether the applicant owns a car (in the Own_Car column, the value is 1 if the applicant owns a car, and is else 0), and\n* whether the applicant owns a home (in the Own_Housing column, the value is 1 if the applicant owns a home, and is else 0)\n\nWhen evaluating fairness, we'll check how the model performs for users in different groups, as identified by the Group column:\n\n* The Group column breaks the users into two groups (where each group corresponds to either 0 or 1).\n* For instance, you can think of the column as breaking the users into two different races, ethnicities, or gender groupings. If the column breaks users into different ethnicities, 0 could correspond to a non-Hispanic user, while 1 corresponds to a Hispanic user.","metadata":{}},{"cell_type":"code","source":"from sklearn import tree\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\n# Train a model and make predictions\nmodel_baseline = tree.DecisionTreeClassifier(random_state=0, max_depth=3)\nmodel_baseline.fit(X_train, y_train)\npreds_baseline = model_baseline.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T23:04:45.105914Z","iopub.execute_input":"2022-11-04T23:04:45.106238Z","iopub.status.idle":"2022-11-04T23:04:45.875477Z","shell.execute_reply.started":"2022-11-04T23:04:45.106211Z","shell.execute_reply":"2022-11-04T23:04:45.874303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This section of code creates a model and trains it with the Decision Tree Classifier, making predictions based on that ML algorithm. ","metadata":{}},{"cell_type":"code","source":"# Function to plot confusion matrix\ndef plot_confusion_matrix(estimator, X, y_true, y_pred, display_labels=[\"Deny\", \"Approve\"],\n                          include_values=True, xticks_rotation='horizontal', values_format='',\n                          normalize=None, cmap=plt.cm.Blues):\n    cm = confusion_matrix(y_true, y_pred, normalize=normalize)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n    return cm, disp.plot(include_values=include_values, cmap=cmap, xticks_rotation=xticks_rotation,\n                     values_format=values_format)\n\n# Function to evaluate the fairness of the model\ndef get_stats(X, y, model, group_one, preds):\n        \n    y_zero, preds_zero, X_zero = y[group_one==False], preds[group_one==False], X[group_one==False]\n    y_one, preds_one, X_one = y[group_one], preds[group_one], X[group_one]\n    \n    print(\"Total approvals:\", preds.sum())\n    print(\"Group A:\", preds_zero.sum(), \"({}% of approvals)\".format(round(preds_zero.sum()/sum(preds)*100, 2)))\n    print(\"Group B:\", preds_one.sum(), \"({}% of approvals)\".format(round(preds_one.sum()/sum(preds)*100, 2)))\n    \n    print(\"\\nOverall accuracy: {}%\".format(round((preds==y).sum()/len(y)*100, 2)))\n    print(\"Group A: {}%\".format(round((preds_zero==y_zero).sum()/len(y_zero)*100, 2)))\n    print(\"Group B: {}%\".format(round((preds_one==y_one).sum()/len(y_one)*100, 2)))\n    \n    cm_zero, disp_zero = plot_confusion_matrix(model, X_zero, y_zero, preds_zero)\n    disp_zero.ax_.set_title(\"Group A\")\n    cm_one, disp_one = plot_confusion_matrix(model, X_one, y_one, preds_one)\n    disp_one.ax_.set_title(\"Group B\")\n    \n    print(\"\\nSensitivity / True positive rate:\")\n    print(\"Group A: {}%\".format(round(cm_zero[1,1] / cm_zero[1].sum()*100, 2)))\n    print(\"Group B: {}%\".format(round(cm_one[1,1] / cm_one[1].sum()*100, 2)))\n    \n# Evaluate the model    \nget_stats(X_test, y_test, model_baseline, X_test[\"Group\"]==1, preds_baseline)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T23:04:45.878679Z","iopub.execute_input":"2022-11-04T23:04:45.879069Z","iopub.status.idle":"2022-11-04T23:04:46.474008Z","shell.execute_reply.started":"2022-11-04T23:04:45.879034Z","shell.execute_reply":"2022-11-04T23:04:46.473204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The confusion matrices above show how the model performs on some test data. We also print additional information (calculated from the confusion matrices) to assess fairness of the model. For instance,\n\n* The model approved 38246 people for a credit card. Of these individuals, 8028 belonged to Group A, and 30218 belonged to Group B.\n* The model is 94.56% accurate for Group A, and 95.02% accurate for Group B. These percentages can be calculated directly from the confusion matrix; for instance, for Group A, the accuracy is (39723+7528)/(39723+500+2219+7528).\n* The true positive rate (TPR) for Group A is 77.23%, and the TPR for Group B is 98.03%. These percentages can be calculated directly from the confusion matrix; for instance, for Group A, the TPR is 7528/(7528+2219).","metadata":{}},{"cell_type":"markdown","source":"# Data Exploration","metadata":{}},{"cell_type":"code","source":"#X[\"Num_Children\"].value_counts(normalize=True)\nX[\"Num_Children\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-11-04T23:04:46.475922Z","iopub.execute_input":"2022-11-04T23:04:46.476646Z","iopub.status.idle":"2022-11-04T23:04:46.492181Z","shell.execute_reply.started":"2022-11-04T23:04:46.476614Z","shell.execute_reply":"2022-11-04T23:04:46.490389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X[\"Own_Car\"].value_counts()\nX[\"Own_Car\"].value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T23:04:46.493764Z","iopub.execute_input":"2022-11-04T23:04:46.494358Z","iopub.status.idle":"2022-11-04T23:04:46.509295Z","shell.execute_reply.started":"2022-11-04T23:04:46.494311Z","shell.execute_reply":"2022-11-04T23:04:46.508205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X[\"Own_Housing\"].value_counts()\nX[\"Own_Housing\"].value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T23:04:46.510710Z","iopub.execute_input":"2022-11-04T23:04:46.511763Z","iopub.status.idle":"2022-11-04T23:04:46.529701Z","shell.execute_reply.started":"2022-11-04T23:04:46.511726Z","shell.execute_reply":"2022-11-04T23:04:46.528805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data from the columns above all show that the current dataset is imbalanced.","metadata":{}},{"cell_type":"code","source":"!pip install fairlearn\n#install package if missing","metadata":{"execution":{"iopub.status.busy":"2022-11-04T23:04:46.531013Z","iopub.execute_input":"2022-11-04T23:04:46.531507Z","iopub.status.idle":"2022-11-04T23:04:59.660033Z","shell.execute_reply.started":"2022-11-04T23:04:46.531477Z","shell.execute_reply":"2022-11-04T23:04:59.658420Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sen_train = X_train[\"Group\"]==1\nsen_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-04T23:04:59.661870Z","iopub.execute_input":"2022-11-04T23:04:59.662248Z","iopub.status.idle":"2022-11-04T23:04:59.674383Z","shell.execute_reply.started":"2022-11-04T23:04:59.662212Z","shell.execute_reply":"2022-11-04T23:04:59.673153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\"Sensitive features to identify groups by\" -FairLearn","metadata":{}},{"cell_type":"code","source":"sen_test = X_test[\"Group\"]==1\nsen_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-04T23:04:59.675995Z","iopub.execute_input":"2022-11-04T23:04:59.676993Z","iopub.status.idle":"2022-11-04T23:04:59.691891Z","shell.execute_reply.started":"2022-11-04T23:04:59.676950Z","shell.execute_reply":"2022-11-04T23:04:59.690861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PostProcessing","metadata":{}},{"cell_type":"markdown","source":"In regards to ML fairness, postprocessing techniques are a series of mitigation algorithms for unfairness that utilize pre-trained models and aim to fit transformation function to that model's outputs in order to improve fairness constraint(s).","metadata":{}},{"cell_type":"markdown","source":"# Threshold Optimizer","metadata":{}},{"cell_type":"markdown","source":"This algorithm takes previously trained models whose results/predictions act as a score to identify certain thresholds for each group. Then the algorithm optimizes a specified objective metric so that it meets specified fairness constraints.","metadata":{}},{"cell_type":"markdown","source":"The code below will use ThresholdOptimizer to maximize the selection_rate compared to the previously trained decision tree in order to make sure the demographic parity is met (selection rate will be the same percentage among groups or at least improved)","metadata":{}},{"cell_type":"markdown","source":"**Demographic Parity**\n\nModel is fair if the composition of people who are selected by the model matches the group membership percentages of the applicants","metadata":{}},{"cell_type":"code","source":"from fairlearn.postprocessing import ThresholdOptimizer\n\n#model_baseline = tree.DecisionTreeClassifier(random_state=0, max_depth=3)\npostprocess_est = ThresholdOptimizer(\n                    estimator=model_baseline,\n                    constraints='demographic_parity',\n                    objective='accuracy_score',\n                    prefit=True,\n                    predict_method = 'auto')\ntopt_model = postprocess_est.fit(X_train, y_train, sensitive_features=sen_train)\npreds_topt = topt_model.predict(X_test, sensitive_features=sen_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T23:04:59.695429Z","iopub.execute_input":"2022-11-04T23:04:59.695805Z","iopub.status.idle":"2022-11-04T23:05:00.256786Z","shell.execute_reply.started":"2022-11-04T23:04:59.695773Z","shell.execute_reply":"2022-11-04T23:05:00.255471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_stats(X_test, y_test, topt_model, sen_test, preds_topt)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T23:05:00.258114Z","iopub.execute_input":"2022-11-04T23:05:00.258456Z","iopub.status.idle":"2022-11-04T23:05:00.767029Z","shell.execute_reply.started":"2022-11-04T23:05:00.258426Z","shell.execute_reply":"2022-11-04T23:05:00.765905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Before**\n> Total approvals: 38246\n> > Group A: 8028 (20.99% of approvals)\n\n> > Group B: 30218 (79.01% of approvals)\n\n**After**\n> Total approvals: 100000\n> > Group A: 49970 (49.97% of approvals)\n\n> > Group B: 50030 (50.03% of approvals)","metadata":{}},{"cell_type":"markdown","source":"**Equal Opportunity**\n\nThis fairness ensures that the proportion of people who should be selected by the model (\"positives\") that are correctly selected by the model is the same for each group. This proportion is referred to as the true positive rate (TPR) or sensitivity of the model.","metadata":{}},{"cell_type":"markdown","source":"**Equal Accuracy**\n\nThe model is fair if the percentage of correct classifications (people who should be denied and are denied, and people who should be approved who are approved) should be the same for each group.","metadata":{}},{"cell_type":"markdown","source":"# AIF 360","metadata":{}},{"cell_type":"markdown","source":"AI Fairness 360 focuses on removing bias by clarifying and labeling groups as unprivileged and privileged. This is another way for their algorithms to detect protected attributes, which are attributes that partition a population into groups whose outcomes should have parity. Examples include race, gender, caste, and religion. Protected attributes are not universal, but are application specific.","metadata":{}},{"cell_type":"markdown","source":"Adult Census Income\nProtected Attributes would be:\n* -Race, privileged: White, unprivileged: Non-white\n* -Sex, privileged: Male, unprivileged: Female","metadata":{}},{"cell_type":"markdown","source":"There are 3 postprocessing algorithms offered by the aif360 package\n* CalibratedEqOddsPostprocessing\n* EqOddsPostprocessing\n* RejectObjectClassification","metadata":{}},{"cell_type":"code","source":"!pip install aif360\n#install package if missing","metadata":{"execution":{"iopub.status.busy":"2022-11-04T23:05:00.768751Z","iopub.execute_input":"2022-11-04T23:05:00.769107Z","iopub.status.idle":"2022-11-04T23:05:12.806231Z","shell.execute_reply.started":"2022-11-04T23:05:00.769075Z","shell.execute_reply":"2022-11-04T23:05:12.804495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"priv_group = X_train['Group']==1\nunpriv_group = X_train['Group']==0","metadata":{"execution":{"iopub.status.busy":"2022-11-04T23:05:41.883659Z","iopub.execute_input":"2022-11-04T23:05:41.884195Z","iopub.status.idle":"2022-11-04T23:05:41.892594Z","shell.execute_reply.started":"2022-11-04T23:05:41.884150Z","shell.execute_reply":"2022-11-04T23:05:41.891166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from aif360.algorithms.postprocessing import CalibratedEqOddsPostprocessing, EqOddsPostprocessing, RejectOptionClassification","metadata":{"execution":{"iopub.status.busy":"2022-11-04T23:05:43.985696Z","iopub.execute_input":"2022-11-04T23:05:43.986511Z","iopub.status.idle":"2022-11-04T23:05:43.991766Z","shell.execute_reply.started":"2022-11-04T23:05:43.986464Z","shell.execute_reply":"2022-11-04T23:05:43.990448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CPP = CalibratedEqOddsPostprocessing(privileged_groups = priv_group,\n                                     unprivileged_groups = unpriv_group,\n                                     cost_constraint='weighted',\n                                     seed=33)\n\nCPP = CPP.fit(model_baseline, preds_baseline)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T02:07:00.468754Z","iopub.execute_input":"2022-11-05T02:07:00.469396Z","iopub.status.idle":"2022-11-05T02:07:00.577010Z","shell.execute_reply.started":"2022-11-05T02:07:00.469277Z","shell.execute_reply":"2022-11-05T02:07:00.575293Z"},"trusted":true},"execution_count":null,"outputs":[]}]}